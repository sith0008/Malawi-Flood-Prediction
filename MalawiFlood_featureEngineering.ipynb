{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Malawi Flood Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data files\n",
    "\n",
    "*train* is provided by the competition organiser. Every row corresponds to a Square which represents a geographical area in southern Malawi. Each Square has rainfall data prior to the floods as well as elevation and land type data.\n",
    "\n",
    "*shapes* is a open-source dataset containing polygons of administrative regions in Malawi\n",
    "\n",
    "*water* is a open-source dataset containing polygons of water bodies in the Africa continent\n",
    "\n",
    "In this way, we can categorise the features we generate into 2 types: Square features and Region features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data files\n",
    "train = pd.read_csv(\"Train.csv\")\n",
    "shapes = gpd.read_file(\"./administrative_polygons/mwi_admbnda_adm3_nso_20181016.shp\")\n",
    "water = gpd.read_file('./water_polygons/Africa_waterbody.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "We define a *haversine* function to calculate the great-circle distance between two sets of coordinates. \n",
    "\n",
    "The *encodePolygon* function is to match each Square to an administrative region provided in *shapes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to match Square_ID to administrative region provided in shape file \n",
    "def encodePolygon(points, polygons):\n",
    "    numPoints = len(points)\n",
    "    numPolygons = len(polygons)\n",
    "    for idx, point in tqdm(enumerate(points)):\n",
    "        row = np.zeros(numPolygons)\n",
    "        for idx2, polygon in enumerate(polygons):\n",
    "            if polygon.contains(point):\n",
    "                row[idx2] = 1\n",
    "                break\n",
    "        if idx == 0:\n",
    "            matrix = row\n",
    "        else:\n",
    "            matrix = np.vstack((matrix,row))\n",
    "    return matrix.transpose()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2015 = train.drop([col for col in train.columns if '2019' in col],axis=1)\n",
    "precip = [i for i in range(1,18)]\n",
    "train2015.columns = ['X','Y','target','elevation']+precip+['LC_Type1_mode','id']\n",
    "train2015['sum'] = train2015[precip].apply(lambda x: x.sum(),axis=1)\n",
    "train2015['mean'] = train2015[precip].apply(lambda x: x.mean(),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Region features\n",
    "\n",
    "Region features refer to features related to each administrative region, for instance, average rainfall in the region and average elevation in the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16466it [01:49, 150.95it/s]\n",
      "/home/hzsit/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/hzsit/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# match Square_ID to administrative region and calculate flooding extent, total rainfall and elevation for each region\n",
    "points = []\n",
    "for point in zip(train2015.X.values,train2015.Y.values):\n",
    "    points.append(Point(point[0],point[1]))\n",
    "polygons = shapes.geometry.values\n",
    "    \n",
    "point_polygon_matrix = encodePolygon(points,polygons)\n",
    "numPoints = point_polygon_matrix.sum(axis=1).transpose()\n",
    "shapes = shapes.assign(num_points = numPoints)\n",
    "\n",
    "# rainfall\n",
    "rainfall = train2015['sum'].values\n",
    "rainfall_polygons = point_polygon_matrix.dot(rainfall.transpose())\n",
    "rainfall_polygons = rainfall_polygons / numPoints\n",
    "# elevation\n",
    "elevation = train2015.elevation.values\n",
    "elevation_polygons = point_polygon_matrix.dot(elevation.transpose())\n",
    "elevation_polygons = elevation_polygons / numPoints\n",
    "\n",
    "shapes = shapes.assign(rainfall=rainfall_polygons)\n",
    "shapes = shapes.assign(elevation=elevation_polygons)\n",
    "\n",
    "shapes = shapes[shapes.num_points!=0]\n",
    "shapes = shapes.reset_index()\n",
    "shapes.columns = ['poly_idx' if x=='index' else x for x in shapes.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes.columns = ['poly_rainfall' if x=='rainfall' else x for x in shapes.columns]\n",
    "shapes.columns = ['poly_elevation' if x=='elevation' else x for x in shapes.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with shapes -- get polygon features\n",
    "a,b = np.where(point_polygon_matrix==1)\n",
    "polygon_map = pd.DataFrame({'poly_idx':a,'square_idx':b})\n",
    "features = train2015.reset_index()\n",
    "features.columns = ['square_idx' if x=='index' else x for x in features.columns]\n",
    "features = features.merge(polygon_map,on='square_idx',how='outer')\n",
    "features.poly_idx = features.poly_idx.fillna(-1)\n",
    "features = features.merge(shapes[['poly_idx','poly_rainfall','poly_elevation']],on='poly_idx',how='left')\n",
    "features.loc[features.poly_rainfall.isna(),'poly_rainfall'] = features['sum']\n",
    "features.loc[features.poly_elevation.isna(),'poly_elevation'] = features['elevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get diff between shape and polygon\n",
    "features['elev_diff'] = features['elevation'] - features['poly_elevation']\n",
    "features['rainfall_diff'] = features['sum'] - features['poly_rainfall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features from water body dataset\n",
    "\n",
    "Using the water body dataset, we can generate an additional Region feature -- number of water bodies in each Region. We can also generate an additional Square feature -- closest water body to each Square. This is useful because from the EDA we see that Squares close to water bodies are most affected by the floods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "833it [00:01, 629.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# get water features (number of water bodies in each region, distance to closest water body)\n",
    "water = water.reset_index()\n",
    "water.columns = ['water_idx' if x=='index' else x for x in water.columns]\n",
    "water['centroid_lng'] = water.geometry.centroid.x\n",
    "water['centroid_lat'] = water.geometry.centroid.y\n",
    "water_centroids = []\n",
    "for poly in water.geometry.values:\n",
    "    water_centroids.append(poly.centroid)\n",
    "\n",
    "water_point_polygon_matrix = encodePolygon(water_centroids,polygons)\n",
    "\n",
    "a,b = np.where(water_point_polygon_matrix==1)\n",
    "water_polygon_map = pd.DataFrame({'poly_idx':a,'water_idx':b})\n",
    "# get number of water bodies in each polygon\n",
    "water_polygon_count = water_polygon_map.groupby('poly_idx').count().reset_index()\n",
    "water_polygon_count.columns = ['poly_idx','water_count']\n",
    "features = features.merge(water_polygon_count,on='poly_idx',how='left')\n",
    "features.water_count = features.water_count.fillna(0)\n",
    "# get distance to closest water body\n",
    "water_polygon_map = water_polygon_map.merge(water[['water_idx','centroid_lng','centroid_lat']],on='water_idx')\n",
    "closest_water= features.merge(water_polygon_map,on='poly_idx',how='left')\n",
    "closest_water= closest_water.dropna()\n",
    "closest_water= closest_water[['square_idx','X','Y','centroid_lng','centroid_lat']]\n",
    "closest_water['water_dist'] = closest_water[['X','Y','centroid_lng','centroid_lat']].apply(lambda x: haversine(x.X,x.Y,x.centroid_lng,x.centroid_lat),axis=1)\n",
    "closest_water = closest_water.groupby('square_idx')['water_dist'].min().to_frame().reset_index()\n",
    "features = features.merge(closest_water,on='square_idx',how='left')\n",
    "features.water_dist = features.water_dist.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['sum','mean','elevation','poly_rainfall','poly_elevation',\n",
    "                'elev_diff','rainfall_diff','water_count','water_dist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_pickle('features.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
